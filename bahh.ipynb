{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import random,logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-8s %(message)s',level = logging.INFO,datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "gene_ontology_file_path = 'DB/go.owl'\n",
    "protein_file_path = 'DB/9606.protein.enrichment.terms.v12.0.txt'\n",
    "protein_links_file_path = 'DB/9606.protein.links.v12.0.txt'\n",
    "protein_full_links_file_path = 'DB/9606.protein.links.detailed.v12.0.txt'\n",
    "semantic_similarity_file_path = 'DB/NegativeSamplesUncertainty.csv'\n",
    "gene_ontology_annotated_file_path = 'DB/go_annotated.owl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedCSV = pd.read_csv('DB/embeddings.csv',index_col=0)\n",
    "embeddings_array = np.array(list(embedCSV.values))\n",
    "dict_embeddings = {embedCSV.index[i]: embeddings_array[i] for i in range(len(embeddings_array))}\n",
    "vector_size = embedCSV.shape[1]\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(label))\n\u001b[1;32m     48\u001b[0m pairs_prots_test \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_data8\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m:\n\u001b[1;32m     50\u001b[0m     pairs_prots_test\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://string-db.org/network/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://string-db.org/network/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     52\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/core/frame.py:12651\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  12577\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m  12578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m  12579\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  12580\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[1;32m  12581\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12649\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[1;32m  12650\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 12651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/core/internals/managers.py:1692\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1692\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/core/internals/managers.py:1733\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m   1732\u001b[0m     rl \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mmgr_locs\n\u001b[0;32m-> 1733\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1734\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1735\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py311/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2588\u001b[0m, in \u001b[0;36mNumpyBlock.get_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: DtypeObj \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[0;32m-> 2588\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(_dtype_obj)\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "#     BaggingClassifier(random_state=42, n_jobs=-1),\n",
    "    XGBClassifier(n_jobs=-1, random_state=42),\n",
    "#     GaussianNB()\n",
    "#    AdaBoostClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "f1_to_csv = {}\n",
    "\n",
    "for i in range(8, -1, -2):\n",
    "    train_data = pd.read_csv(\"DB/TRAIN/train_data\" + str(i) + \".csv\", sep=\",\", header=0)\n",
    "\n",
    "    pairs_prots = []\n",
    "    for d in train_data.values:\n",
    "        pairs_prots.append(('https://string-db.org/network/' + d[0],'https://string-db.org/network/' + d[1], 1))\n",
    "    \n",
    "    negative_train = pd.read_csv(\"DB/TRAIN/negative_train\" + str(i) + \".csv\", sep=\",\", header=0).values\n",
    "\n",
    "    for j in range(5):\n",
    "\n",
    "        test_data8 = pd.read_csv(\"DB/TEST/test_data\" + str(j) + \".csv\", sep=\",\", header=0)\n",
    "        negative_test = pd.read_csv(\"DB/TEST/negative_pairs_prots\" + str(j) + \".csv\", sep=\",\", header=0).values\n",
    "\n",
    "        # Sample weight\n",
    "        # sample_weight = list(data['combined_score'].values)\n",
    "        # sample_weight.extend([mean for i in range(0, len(pairs_prots))])\n",
    "        # sample_weight = np.array(sample_weight)\n",
    "\n",
    "        # sample_weight = np.exp(0.1 * (sample_weight - 700))\n",
    "\n",
    "        # Generating pair representations using hadamard operator # other possibilities are concatenation, wl-1 or wl-2\n",
    "        X_train, y_train = [], []\n",
    "        for prot1, prot2, label in pairs_prots:\n",
    "            emb_prot1 = dict_embeddings[prot1].reshape(1, vector_size)\n",
    "            emb_prot2 = dict_embeddings[prot2].reshape(1, vector_size)\n",
    "            hada = np.multiply(emb_prot1, emb_prot2)\n",
    "            X_train.append(hada.tolist()[0])\n",
    "            y_train.append(int(label))\n",
    "\n",
    "        for prot1, prot2, label in negative_train:\n",
    "            emb_prot1 = dict_embeddings[prot1].reshape(1, vector_size)\n",
    "            emb_prot2 = dict_embeddings[prot2].reshape(1, vector_size)\n",
    "            hada = np.multiply(emb_prot1, emb_prot2)\n",
    "            X_train.append(hada.tolist()[0])\n",
    "            y_train.append(int(label))\n",
    "\n",
    "        pairs_prots_test = []\n",
    "        for d in test_data8.values:\n",
    "            pairs_prots_test.append(('https://string-db.org/network/' + d[0],'https://string-db.org/network/' + d[1], 1))\n",
    "\n",
    "        X_test, y_test = [], []\n",
    "        for prot1, prot2, label in pairs_prots_test:\n",
    "            emb_prot1 = dict_embeddings[prot1].reshape(1, vector_size)\n",
    "            emb_prot2 = dict_embeddings[prot2].reshape(1, vector_size)\n",
    "            hada = np.multiply(emb_prot1, emb_prot2)\n",
    "            X_test.append(hada.tolist()[0])\n",
    "            y_test.append(int(label))\n",
    "\n",
    "        for prot1, prot2, label in negative_test:\n",
    "            emb_prot1 = dict_embeddings[prot1].reshape(1, vector_size)\n",
    "            emb_prot2 = dict_embeddings[prot2].reshape(1, vector_size)\n",
    "            hada = np.multiply(emb_prot1, emb_prot2)\n",
    "            X_test.append(hada.tolist()[0])\n",
    "            y_test.append(int(label))\n",
    "\n",
    "        #sample_weight_train = sample_weight[train_index]\n",
    "\n",
    "        logging.info(\"Training with threshold: \" + str(i) + \" and fold: \" + str(j))\n",
    "\n",
    "        for clf in classifiers:\n",
    "\n",
    "            logging.info(\"Training with classifier: \" + type(clf).__name__)\n",
    "\n",
    "            clf.fit(X_train, y_train)\n",
    "            # Obtaining predictions\n",
    "            pred_test = clf.predict(X_test)\n",
    "            # Computing performance metrics\n",
    "            weighted_avg_f1 = metrics.f1_score(y_test, pred_test, average='weighted')\n",
    "            \n",
    "            n = type(clf).__name__\n",
    "            if n not in f1_to_csv :\n",
    "                f1_to_csv[n] = {}   \n",
    "\n",
    "            if i not in f1_to_csv[n] :\n",
    "                f1_to_csv[n][i] = [weighted_avg_f1]\n",
    "            else :\n",
    "                f1_to_csv[n][i].append(weighted_avg_f1)\n",
    "    \n",
    "for v in f1_to_csv.keys():\n",
    "    df = pd.DataFrame.from_dict(f1_to_csv[v], orient='index')\n",
    "    df.to_csv('Results/f1_results_negsWexp01_' + v + '_Fraction10.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
